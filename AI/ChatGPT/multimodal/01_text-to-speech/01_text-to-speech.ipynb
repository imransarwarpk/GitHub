{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/text-to-speech\n",
    "\n",
    "## Voice options\n",
    "Experiment with different voices (alloy, echo, fable, onyx, nova, and shimmer) to find one that matches your desired tone and audience. The current voices are optimized for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\AI\\ChatGPT\\multimodal\\01_text-to-speech\\01_text-to-speech.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/AI/ChatGPT/multimodal/01_text-to-speech/01_text-to-speech.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m client \u001b[39m=\u001b[39m OpenAI()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/AI/ChatGPT/multimodal/01_text-to-speech/01_text-to-speech.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m speech_file_path : \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mspeech.mp3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/AI/ChatGPT/multimodal/01_text-to-speech/01_text-to-speech.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49maudio\u001b[39m.\u001b[39;49mspeech\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/AI/ChatGPT/multimodal/01_text-to-speech/01_text-to-speech.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtts-1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/AI/ChatGPT/multimodal/01_text-to-speech/01_text-to-speech.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   voice\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39malloy\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/AI/ChatGPT/multimodal/01_text-to-speech/01_text-to-speech.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mToday is a wonderful day to build something people love!\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/AI/ChatGPT/multimodal/01_text-to-speech/01_text-to-speech.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/AI/ChatGPT/multimodal/01_text-to-speech/01_text-to-speech.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m response\u001b[39m.\u001b[39mstream_to_file(speech_file_path)\n",
      "File \u001b[1;32mc:\\Users\\IMRAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\audio\\speech.py:71\u001b[0m, in \u001b[0;36mSpeech.create\u001b[1;34m(self, input, model, voice, response_format, speed, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m     31\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m     44\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m HttpxBinaryResponseContent:\n\u001b[0;32m     45\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m    Generates audio from the input text.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m     72\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/audio/speech\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     73\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m     74\u001b[0m             {\n\u001b[0;32m     75\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39minput\u001b[39;49m,\n\u001b[0;32m     76\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m     77\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mvoice\u001b[39;49m\u001b[39m\"\u001b[39;49m: voice,\n\u001b[0;32m     78\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[0;32m     79\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mspeed\u001b[39;49m\u001b[39m\"\u001b[39;49m: speed,\n\u001b[0;32m     80\u001b[0m             },\n\u001b[0;32m     81\u001b[0m             speech_create_params\u001b[39m.\u001b[39;49mSpeechCreateParams,\n\u001b[0;32m     82\u001b[0m         ),\n\u001b[0;32m     83\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m     84\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m     85\u001b[0m         ),\n\u001b[0;32m     86\u001b[0m         cast_to\u001b[39m=\u001b[39;49mHttpxBinaryResponseContent,\n\u001b[0;32m     87\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\IMRAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1086\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1073\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1074\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1082\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1083\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1084\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1085\u001b[0m     )\n\u001b[1;32m-> 1086\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\IMRAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:846\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    838\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    839\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    844\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    845\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 846\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    847\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    848\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    849\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    850\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    851\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    852\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\IMRAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:884\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    883\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 884\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    885\u001b[0m         options,\n\u001b[0;32m    886\u001b[0m         cast_to,\n\u001b[0;32m    887\u001b[0m         retries,\n\u001b[0;32m    888\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    889\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    890\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\IMRAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:956\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    954\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    957\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    958\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    959\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    960\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    961\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    962\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\IMRAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:884\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    883\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 884\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    885\u001b[0m         options,\n\u001b[0;32m    886\u001b[0m         cast_to,\n\u001b[0;32m    887\u001b[0m         retries,\n\u001b[0;32m    888\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    889\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    890\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\IMRAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:956\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    954\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    957\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    958\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    959\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    960\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    961\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    962\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\IMRAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:898\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    895\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m    896\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 898\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    900\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "speech_file_path : str = \"speech.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Today is a wonderful day to build something people love!\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported languages\n",
    "\n",
    "The TTS model generally follows the Whisper model in terms of language support. Whisper supports the following languages and performs well despite the current voices being optimized for English:\n",
    "\n",
    "Afrikaans, Arabic, Armenian, Azerbaijani, Belarusian, Bosnian, Bulgarian, Catalan, Chinese, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, Galician, German, Greek, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Italian, Japanese, Kannada, Kazakh, Korean, Latvian, Lithuanian, Macedonian, Malay, Marathi, Maori, Nepali, Norwegian, Persian, Polish, Portuguese, Romanian, Russian, Serbian, Slovak, Slovenian, Spanish, Swahili, Swedish, Tagalog, Tamil, Thai, Turkish, Ukrainian, Urdu, Vietnamese, and Welsh.\n",
    "\n",
    "You can generate spoken audio in these languages by providing the input text in the language of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "speech_file_path : str = \"urdu.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"میرا نام محمد قاسم ہے\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create file **01_text-to-speech.py**\n",
    "\n",
    "\n",
    "```\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "speech_file_path = Path(__file__).parent / \"speech.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Today is a wonderful day to build something people love!\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python 01_text-to-speech.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming real time audio\n",
    "The Speech API provides support for real time audio streaming using chunk transfer encoding. This means that the audio is able to be played before the full file has been generated and made accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Hello world! This is a streaming test.\",\n",
    ")\n",
    "\n",
    "response.stream_to_file(\"streaming.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
